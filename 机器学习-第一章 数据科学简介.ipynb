{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一章 数据科学简介  \n",
    "* https://blog.csdn.net/ritterliu/article/details/54821300  （非常好的综述文章）\n",
    "　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　　2016年3月，Google DeepMind的AlphaGo打败了韩国的围棋大师李世石九段，让人工智能赢得了前所未有的关注，真正掀起了人工智能AI热潮，开启了一个新的纪元。    \n",
    "<img src=\"./data_picture/chapter1/sjkxjjt1.png\" width=\"400\" height=\"300\" alt=\"围棋世界大战\" align=center> \n",
    "　　在媒体描述DeepMind胜利的时候，将人工智能（AI）、机器学习（machine learning）和深度学习（deep learning）都用上了。这三者在AlphaGo击败李世乭的过程中都起了作用，但它们说的并不是一回事。  \n",
    "　　最简单的可视化方法地展现出它们三者的关系和应用。  \n",
    "<img src=\"./data_picture/chapter1/sjkxjjt2.png\" width=\"500\" height=\"400\" align=center> \n",
    "　　如上图，人工智能是最早出现的，也是最大、最外侧的矩形；其次是机器学习，稍晚一点；最内侧，是深度学习，当今人工智能大爆炸的核心驱动。  \n",
    "　　五十年代，人工智能曾一度被极为看好。之后，人工智能的一些较小的子集发展了起来，先是机器学习，然后是深度学习。深度学习又是机器学习的子集。深度学习造成了前所未有的巨大的影响。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.人工智能  \n",
    "　　“人工智能”一词最初是在1956 年Dartmouth学会上提出的。从那以后，研究者们发展了众多理论和原理，人工智能的概念也随之扩展。人工智能（Artificial Intelligence），英文缩写为AI。它是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学。  \n",
    "　　强人工智能(BOTTOM-UP AI)  \n",
    "　　强人工智能观点认为有可能制造出真正能推理（REASONING）和解决问题（PROBLEM_SOLVING）的智能机器，并且，这样的机器能将被认为是有知觉的，有自我意识的。  \n",
    "　　弱人工智能(TOP-DOWN AI)  \n",
    "　　弱人工智能观点认为不可能制造出能真正地推理（REASONING）和解决问题（PROBLEM_SOLVING）的智能机器，这些机器只不过看起来像是智能的，但是并不真正拥有智能，也不会有自主意识。  \n",
    "　　主流科研集中在弱人工智能上，并且一般认为这一研究领域已经取得可观的成就。强人工智能的研究则处于停滞不前的状态下。  \n",
    "　　1956年，几个计算机科学家相聚在达特茅斯会议，提出了“人工智能”的概念，梦想着用当时刚刚出现的计算机来构造复杂的、拥有与人类智慧同样本质特性的机器。其后，人工智能就一直萦绕于人们的脑海之中，并在科研实验室中慢慢孵化。之后的几十年，人工智能一直在两极反转，或被称作人类文明耀眼未来的预言，或被当成技术疯子的狂想扔到垃圾堆里。直到2012年之前，这两种声音还在同时存在。  \n",
    "　　2012年以后，得益于数据量的上涨、运算力的提升和机器学习新算法（深度学习）的出现，人工智能开始大爆发。据领英近日发布的《全球AI领域人才报告》显示，截至2017年一季度，基于领英平台的全球AI（人工智能）领域技术人才数量超过190万，仅国内人工智能人才缺口达到500多万。  \n",
    "　　人工智能的研究领域也在不断扩大，图二展示了人工智能研究的各个分支，包括专家系统、机器学习、进化计算、模糊逻辑、计算机视觉、自然语言处理、推荐系统、知识图谱等。  \n",
    "<img src=\"./data_picture/chapter1/sjkxjjt3.png\" width=\"350\" height=\"300\" align=center>  \n",
    "　　人工智能的应用场景：  \n",
    "　　应用场景需要实现最基本的功能：看、听、说、读、写、译    \n",
    "　　看：图像识别  \n",
    "　　听和说：语音识别，将将语音和文字互相转换（科大讯飞）  \n",
    "　　读：情感分析、文本聚类、关键词提取  \n",
    "　　写：能够写唐诗、写作文、智能文字客服、结合语音识别能够智能问答。  \n",
    "　　译：能够实现多国语言互相翻译。  \n",
    "　　人工智能特点：  \n",
    "　　特点：感知（图像识别、语音识别）+认知+应用  \n",
    "　　核心：自然语言处理  \n",
    "　　应用：无人驾驶、智能音箱、人脸识别、机器翻译、AlphaGo等。   \n",
    "<img src=\"./data_picture/chapter1/sjkxjjt4.png\" width=\"350\" height=\"300\" align=center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ２.  机器学习：一种实现人工智能的方法  \n",
    " \n",
    "　　机器学习最基本的做法，是使用算法来解析数据、从中学习，然后对真实世界中的事件做出决策和预测。与传统的为解决特定任务、硬编码的软件程序不同，机器学习是用大量的数据来“训练”，通过各种算法从数据中学习如何完成任务。  \n",
    "　　机器学习直接来源于早期的人工智能领域。从学习方法上来分，机器学习算法可以分为监督学习（如分类问题）、无监督学习（如聚类问题）、半监督学习、集成学习、深度学习和强化学习。传统的算法包括决策树、聚类、贝叶斯分类、支持向量机、EM、Adaboost、神经网络等等  \n",
    "<img src=\"./data_picture/chapter1/jqxxxgxkt.png\" width=\"500\" height=\"400\" align=center>  \n",
    "* 模式识别  \n",
    "　　模式识别=机器学习。两者的主要区别在于前者是从工业界发展起来的概念，后者则主要源自计算机学科。在著名的《Pattern Recognition And Machine Learning》这本书中，Christopher M. Bishop在开头是这样说的“模式识别源自工业界，而机器学习来自于计算机学科。不过，它们中的活动可以被视为同一个领域的两个方面，同时在过去的10年间，它们都有了长足的发展”。　　  \n",
    "* 数据挖掘    \n",
    "　　数据挖掘=机器学习+数据库。  \n",
    "* 统计学习  \n",
    "　　统计学习近似等于机器学习。统计学习是个与机器学习高度重叠的学科。因为机器学习中的大多数方法来自统计学，甚至可以认为，统计学的发展促进机器学习的繁荣昌盛。例如著名的支持向量机算法，就是源自统计学科。但是在某种程度上两者是有分别的，这个分别在于：统计学习者重点关注的是统计模型的发展与优化，偏数学，而机器学习者更关注的是能够解决问题，偏实践，因此机器学习研究者会重点研究学习算法在计算机上执行的效率与准确性的提升。    　\n",
    "* 计算机视觉  \n",
    "　　计算机视觉=图像处理+机器学习。图像处理技术用于将图像处理为适合进入机器学习模型中的输入，机器学习则负责从图像中识别出相关的模式。计算机视觉相关的应用非常的多，例如百度识图、手写字符识别、车牌识别等等应用。这个领域是应用前景非常火热的，同时也是研究的热门方向。随着机器学习的新领域深度学习的发展，大大促进了计算机图像识别的效果，因此未来计算机视觉界的发展前景不可估量。      \n",
    "* 语音识别  \n",
    "　　语音识别=语音处理+机器学习。语音识别就是音频处理技术与机器学习的结合。语音识别技术一般不会单独使用，一般会结合自然语言处理的相关技术。  \n",
    "* 自然语言处理  \n",
    "　　自然语言处理=文本处理+机器学习。自然语言处理技术主要是让机器理解人类的语言的一门领域。在自然语言处理技术中，大量使用了编译原理相关的技术，例如词法分析，语法分析等等，除此之外，在理解这个层面，则使用了语义理解，机器学习等技术。作为唯一由人类自身创造的符号，自然语言处理一直是机器学习界不断研究的方向。按照百度机器学习专家余凯的说法“听与看，说白了就是阿猫和阿狗都会的，而只有语言才是人类独有的”。如何利用机器学习技术进行自然语言的的深度理解，一直是工业和学术界关注的焦点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 深度学习：一种实现机器学习的技术   \n",
    "　　深度学习算法主要包括：卷积神经网络、循环神经网络、生成式对抗网络、强化学习等。    \n",
    "　　深度学习的概念由Hinton等人于2006年提出。基于深信度网(DBN)提出非监督贪心逐层训练算法。此外Lecun等人提出的卷积神经网络是第一个真正多层结构学习算法，经过训练可以很好的提取图像特征，从而在计算机视觉领域中有着广泛的应用。  \n",
    "<img src=\"./data_picture/chapter1/ntjc21.png\" width=\"400\" height=\"300\" align=center> \n",
    "　　循环神经网络（RNN）是一种十分重要的神经网络模型。由于其具有记忆特性，可以处理前后输入有关系的序列数据，从而在自然语言处理领域中有着广泛的应用。  \n",
    "<img src=\"./data_picture/chapter1/deep_rnn.png\" width=\"400\" height=\"300\" align=center> \n",
    "　　深度学习摧枯拉朽般地实现了各种任务，使得似乎所有的机器辅助功能都变为可能。无人驾驶汽车，预防性医疗保健，甚至是更好的电影推荐，都近在眼前，或者即将实现。其原因与以下因素息息相关：  \n",
    "　　首先，深度神经网络需要大量数据进行训练。网络深度太浅的话，识别能力往往不如一般的浅层模型，比如SVM或者boosting；如果做得很深，就需要大量数据进行训练，否则机器学习中的过拟合将不可避免。而2006年开始，正好是互联网开始大量产生各种各样的图片数据的时候，即视觉大数据开始爆发式地增长。文本数据量本来就很多，因此随着循环神经网络的发展，极大的推动了自然语言处理的进步。  \n",
    "　　其次，是运算能力。深度神经网络对计算机的运算要求比较高，需要大量重复可并行化的计算，在当时CPU只有单核且运算能力比较低的情况下，不可能进行很深的神经网络的训练。随着GPU计算能力的增长，神经网络结合大数据的训练才成为可能。  \n",
    "　　最后，就是人和。深度神经网络有一批一直在坚持的科学家（如Lecun、Hinton、Bengio等人）才没有被沉没，才没有被海量的浅层方法淹没。最后终于看到深度神经网络占领主流的曙光，最终极大地推动了人工智能的发展。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 深度学习知名专家  \n",
    "<img src=\"./data_picture/chapter1/sjkxjjt5.png\" width=\"600\" height=\"300\" align=center>   \n",
    "　　这幅图上的三人是当今机器学习界的执牛耳者。中间的是Geoffrey Hinton, 加拿大多伦多大学的教授，如今被聘为“Google大脑”的负责人。右边的是Yann LeCun, 纽约大学教授，如今是Facebook人工智能实验室的主任。左边的Yoshua Bengio，蒙特利尔大学计算机科学与运筹学系(DIRO)的教授，加拿大统计学习算法研究主席。  \n",
    "　　三大牛Yann LeCun、Yoshua Bengio和Geoffrey Hinton在深度学习领域的地位无人不知。为纪念人工智能提出60周年，最新的《Nature》杂志专门开辟了一个“人工智能 + 机器人”专题 ，发表多篇相关论文，其中包括了Yann LeCun、Yoshua Bengio和Geoffrey Hinton首次合作的这篇综述文章“Deep Learning”，下边链接该综述文章中文译文。  \n",
    "（深度学习联合综述（上）：https://www.csdn.net/article/2015-06-01/2824811）  \n",
    "（深度学习联合综述（下）：https://www.csdn.net/article/2015-06-02/2824825）  \n",
    "\n",
    "<img src=\"./data_picture/chapter1/sjkxjjt6.png\" width=\"200\" height=\"200\" align=center>   \n",
    "　　还有一位科学家，吴恩达（1976-，英文名：Andrew Ng），华裔美国人，是斯坦福大学计算机科学系和电子工程系副教授，人工智能实验室主任。吴恩达是人工智能和机器学习领域国际上最权威的学者之一。吴恩达也是在线教育平台Coursera的联合创始人（withDaphne Koller），为机器学习理论和应用的推广起到了巨大的作用。  \n",
    "　　2014年5月16日，吴恩达离开谷歌加入百度，担任百度公司首席科学家，负责百度研究院的领导工作，尤其是Baidu Brain计划。 2017年离开百度。  \n",
    "\n",
    "<img src=\"./data_picture/chapter1/sjkxjjt7.png\" width=\"300\" height=\"300\" align=center>   \n",
    "　　还有一位美籍华人女科学家，李飞飞（1976-），1999年毕业于普林斯顿大学后，她赴西藏研究一年藏药；2005年获得加州理工学院电子工程博士学位；2009年加入斯坦福大学任助理教授，2013年—2018年担任斯坦福人工智能实验室主任；2017年1月4日，入职谷歌任谷歌云AI负责人；2018年9月离开谷歌返回斯坦福大学担任教授；2020年2月，李飞飞教授当选为美国国家工程院士。她倡导的 ImageNet 竞赛，每年都牵动着整个业界的心弦。她的高质量论文，在顶级期刊发表超过100篇，被引用高达4万余次。2015年她入选“世界百大思想者”。  \n",
    "（https://www.sohu.com/a/232611147_99934359  李飞飞经历）  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video id=\"video\" controls=\"\" preload=\"none\">\n",
    "    <source id=\"mp4\" src=\"/home/liuqiang/Documents/ImproveSelf/情感心理学/71329742-1-6.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
