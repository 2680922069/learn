{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三章 K近邻法（KNN）\n",
    "* https://baike.baidu.com/item/k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/9512781?fr=aladdin  （算法讲这个）\n",
    "* https://www.cnblogs.com/21207-iHome/p/6084670.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* KNN可用于分类和回归，用于分类时是多分类方法。\n",
    "* KNN法1968年由Cover和Hart提出，此方法没有学习训练过程。\n",
    "* 重要说明1：由于方法用到了距离，而且距离值直接影响到聚类效果，因此在聚类前必须对每一个特征数据进行标准化或归一化处理。\n",
    "* 重要说明2：由于此方法根据预测点近邻的各类点的个数多少来确定该预测点的类别，因此原始类别数据不均衡，将严重影响最终分类效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.KNN方法\n",
    "* KNN分类主要思想：选择距离未知样本最近的K个训练样本，该K个样本大多数属于某一类型（可考虑距离加权），则未知样本判定为该类型。\n",
    "* KNN回归主要思想：选择距离未知样本最近的K个训练样本，该K个样本对应的值的平均值就是该未知样本的预测值（求平均值时可考虑距离加权）。\n",
    "* KNN三要素：k值选择、距离选择、分类(回归)决策规则(分类一般用投票表决，回归一般用均值)\n",
    "* 关键点：k值的选择问题，k值太小时，模型过于复杂，会出现过拟合；k值过大，模型过于简单，训练结果和预测结果都会不准确，即出现欠拟合。实际应用中，k值一般先取一个较小的值，然后采用交叉验证的方法来选取最优的k值。\n",
    "* k近邻法实现问题：k近邻法最简单的实现就是线性扫描，这时要计算输入实例与每一个训练实例的距离，当训练集很大时，计算量太大。为了提高k近邻方法搜索的效率，考虑使用特殊结构存储训练数据，以减少计算距离的次数，具体方法很多，李航书中介绍了kd树方法（P43）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.实例1：使用KNN完成乳腺癌检测分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 乳腺癌检测分类数据集说明\n",
    "* 乳腺癌检测数据集：数据集共有569个样本，每个样本有30个特征，其中357个阳性，212个阴性。\n",
    "特征名称意义：  \n",
    "![caption](./data_picture/chapter3/cancer_data.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...    worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...            17.33           184.60      2019.0   \n",
       "1                 0.05667  ...            23.41           158.80      1956.0   \n",
       "2                 0.05999  ...            25.53           152.50      1709.0   \n",
       "3                 0.09744  ...            26.50            98.87       567.7   \n",
       "4                 0.05883  ...            16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  class  \n",
       "0          0.4601                  0.11890      0  \n",
       "1          0.2750                  0.08902      0  \n",
       "2          0.3613                  0.08758      0  \n",
       "3          0.6638                  0.17300      0  \n",
       "4          0.2364                  0.07678      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.数据读取\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "data=pd.read_csv('./data_picture/chapter3/breast-cancer.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成训练集和测试集\n",
    "X=data.drop('class',axis=1)\n",
    "y=data['class']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.训练KNN模型\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#数据标准化（如果不考虑舍入误差的影响，对特征和label的数据标准化只影响速度，不影响预测效果）\n",
    "ss=StandardScaler()\n",
    "scale=ss.fit(X_train)\n",
    "X_train=scale.transform(X_train)\n",
    "X_test=scale.transform(X_test)\n",
    "\n",
    "#建立模型并预测\n",
    "model=KNeighborsClassifier()  \n",
    "model.fit(X_train,y_train)#此时y_train的值是字符型，k近邻方法能自动处理非数值型label列。\n",
    "                        #sklearn中的分类器应该都能有这个功能，但特征列中的非数值型数据需要自编程序处理为数值型数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的模型评估指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       158\n",
      "           1       0.97      0.99      0.98       268\n",
      "\n",
      "    accuracy                           0.97       426\n",
      "   macro avg       0.97      0.97      0.97       426\n",
      "weighted avg       0.97      0.97      0.97       426\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "测试集的模型评估指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        54\n",
      "           1       0.96      0.99      0.97        89\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.96      0.96       143\n",
      "weighted avg       0.97      0.97      0.96       143\n",
      "\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#3.模型评估\n",
    "print(\"训练集的模型评估指标：\")\n",
    "y_train_predict=model.predict(X_train)\n",
    "model_report1=classification_report(y_train,y_train_predict)\n",
    "print(model_report1)\n",
    "print('$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$')\n",
    "\n",
    "print(\"测试集的模型评估指标：\")\n",
    "y_predict=model.predict(X_test)\n",
    "model_report=classification_report(y_test,y_predict)\n",
    "print(model_report)\n",
    "print('--------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_knn.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4.模型保存\n",
    "import joblib\n",
    "joblib.dump(model,'model_knn.pkl')  #保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.KNN模型预测\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#模型导入\n",
    "##利用调入的模型对数据进行预测时，要保证待预测数据和模型训练时的数据格式一致，例如如果训练时数据做了标准化，\n",
    "import joblib                                                              #则待预测数据必须做相应的标准化。\n",
    "model=joblib.load('model_knn.pkl')     #调入模型\n",
    "\n",
    "#数据标准化（如果不考虑舍入误差的影响，对特征和label的数据标准化只影响速度，不影响预测效果）\n",
    "ss=StandardScaler()\n",
    "scale=ss.fit(X_train)\n",
    "X_train=scale.transform(X_train)\n",
    "X_test=scale.transform(X_test)\n",
    "\n",
    "#模型预测\n",
    "y_pred=model.predict(X_test)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注：关于分类模型评价指标说明：\n",
    "![caption](./data_picture/chapter3/pgt1.jpg)\n",
    "![caption](./data_picture/chapter3/pgt2.jpg)\n",
    "![caption](./data_picture/chapter3/pgt3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.实例2：利用KNN对美国波士顿地区房价数据进行回归预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　　该数据集是一个回归问题。每个类的观察值数量是均等的，共有 506 个观察，13 个输入变量和1个输出变量。  \n",
    "　　每条数据包含房屋以及房屋周围的详细信息。其中包含城镇犯罪率，一氧化氮浓度，住宅平均房间数，到中心区域的加权距离以及自住房平均房价等等。  \n",
    "\n",
    "　　CRIM：城镇人均犯罪率。  \n",
    "　　ZN：住宅用地超过 25000 sq.ft. 的比例。  \n",
    "　　INDUS：城镇非零售商用土地的比例。  \n",
    "　　CHAS：查理斯河空变量（如果边界是河流，则为1；否则为0）。  \n",
    "　　NOX：一氧化氮浓度。  \n",
    "　　RM：住宅平均房间数。  \n",
    "　　AGE：1940 年之前建成的自用房屋比例。  \n",
    "　　DIS：到波士顿五个中心区域的加权距离。  \n",
    "　　RAD：辐射性公路的接近指数。  \n",
    "　　TAX：每 10000 美元的全值财产税率。  \n",
    "　　PTRATIO：城镇师生比例。  \n",
    "　　B：1000（Bk-0.63）^ 2，其中 Bk 指代城镇中黑人的比例。  \n",
    "　　LSTAT：人口中地位低下者的比例。  \n",
    "　　MEDV：自住房的平均房价，以千美元计。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.数据读入\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "data=pd.read_csv('./data_picture/chapter3/boston_house_prices.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.生成训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=data.drop('MEDV',axis=1)   #生成特征集\n",
    "y=data['MEDV']               #生成labels集\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=33,test_size=0.25)  #生成训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.数据标准化处理\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss_X=StandardScaler()\n",
    "scaler_X=ss_X.fit(X_train)\n",
    "X_train=scaler_X.transform(X_train)\n",
    "X_test=scaler_X.transform(X_test)\n",
    "\n",
    "#4.建立KNN回归模型\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model=KNeighborsRegressor(n_neighbors=5)\n",
    "model.fit(X_train,y_train)   #y_train可以是行向量也可以是列向量，knn会自动将y_train转换为列向量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集回归评估指标：\n",
      "The value of R2: R2= 0.8581070787652896\n",
      "The value of mean_squared_error: MSE= 12.21917678100264\n",
      "The value of mean_absolute_error: MAE= 2.2037994722955143\n",
      "---------------------------------------------------------------------------\n",
      "测试集回归评估指标：\n",
      "The value of R2: R2= 0.6907212176346005\n",
      "The value of mean_squared_error: MSE= 23.981877165354334\n",
      "The value of mean_absolute_error: MAE= 2.9650393700787396\n"
     ]
    }
   ],
   "source": [
    "#5.模型评估（模型自带评估模块就是做好的评估指标）\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error \n",
    "print('训练集回归评估指标：')\n",
    "\n",
    "y_train_predict=model.predict(X_train)\n",
    "R2_train=r2_score(y_train,y_train_predict)  #拟合优度值\n",
    "print('The value of R2:','R2=',R2_train)\n",
    "mse=mean_squared_error(y_train,y_train_predict)   #均方误差\n",
    "print('The value of mean_squared_error:','MSE=',mse)\n",
    "mae=mean_absolute_error(y_train,y_train_predict)  #平均绝对值误差\n",
    "print('The value of mean_absolute_error:','MAE=',mae)\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('测试集回归评估指标：')\n",
    "y_test_predict=model.predict(X_test)\n",
    "R2_test=r2_score(y_test,y_test_predict)  #拟合优度值\n",
    "print('The value of R2:','R2=',R2_test)\n",
    "mse=mean_squared_error(y_test,y_test_predict)   #均方误差\n",
    "print('The value of mean_squared_error:','MSE=',mse)\n",
    "mae=mean_absolute_error(y_test,y_test_predict)  #平均绝对值误差\n",
    "print('The value of mean_absolute_error:','MAE=',mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注：关于回归模型评价指标说明：\n",
    "![caption](./data_picture/chapter3/pgt8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.1 18.1]\n"
     ]
    }
   ],
   "source": [
    "#6.对新的未知数据做预测\n",
    "#此处做预测一定要把数据逆变换回去，因为模型预测的结果是标准化后的数据。\n",
    "\n",
    "new_data=np.array([[0.22489,12.5,7.87,0,0.524,6.377,94.3,6.3467, 5.,311,15.2,392.52,20.45],\n",
    "                   [0.3489,11.5,7.7,0,0.526,6.477,94.3,16.3467, 5.,313,15.2,392.55,20.45]])\n",
    "X_new=scaler_X.transform(new_data) #标准化\n",
    "y_new=model.predict(X_new)        #预测\n",
    "print(y_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
