{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第七章 神经网络  \n",
    "* https://blog.csdn.net/u014303046/article/details/78200010  \n",
    "* 可做多分类和回归；神经网络分类算法中去掉输出层的激活函数就可以做回归。\n",
    "* 神经网络的优势：神经网络应用在分类问题中效果很好。工业界中分类问题居多。LR或者linear SVM更适用线性分割。如果数据非线性可分（现实生活中多是非线性的），LR通常需要靠特征工程做特征映射，增加高斯项或者组合项；SVM需要选择核。 而增加高斯项、组合项会产生很多没有用的维度，增加计算量。GBDT可以使用弱的线性分类器组合成强分类器，但维度很高时效果可能并不好。\n",
    "* 常规神经网络存在的问题：层数不能太多，也就是两层左右吧，因为层数增加误差反向传播逐步失效；另外即使层数能增加又需要大量的数据；极易出现过拟合，但可以处理。存在黑匣子，不能很好的直观理解内部结构。不适合处理数据量不大的问题，因为对于给定的特征数和分类数，即使只取一层或两层，待求的未知权重矩阵包含的未知量也是很多的，和其它方法相比，同一个问题神经网络方法待求参数过多。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、BP神经网络原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (一)神经网络结构\n",
    "1.神经元  \n",
    "　　像人类大脑神经元一样，神经元构成了基本的神经网络。神经元接收输入，处理它并产生输出。\n",
    "<img src=\"./data_picture/chapter7/ntjc1.png\" width=\"400\" height=\"300\" alt=\"围棋世界大战\" align=center>  \n",
    "2.神经网络模型（多层感知器MLP）  \n",
    "　　单个神经元无法执行高度复杂的任务。因此，使用堆栈的神经元来生成需要的输出。  \n",
    "（1）单隐层神经网络模型  \n",
    "　　最简单的网络中，有一个输入层、一个隐藏层和一个输出层。每个层都有多个神经元，并且每个层中的所有神经元都连接到下一层的所有神经元。这些网络也可以被称为完全连接的网络。  \n",
    "<img src=\"./data_picture/chapter7/ntjc2.png\" width=\"600\" height=\"400\" alt=\"围棋世界大战\" align=center> \n",
    "（2）多隐层神经网络模型图  \n",
    "<img src=\"./data_picture/chapter7/ntjc3.png\" width=\"550\" height=\"400\" alt=\"围棋世界大战\" align=center> \n",
    "3.常用激活函数  \n",
    "（1）逻辑函数Sigmoid(x)   \n",
    "　　逻辑函数（logistic function）或逻辑曲线（logistic curve）是一种常见的S函数，它是皮埃尔·弗朗索瓦·韦吕勒在1844或1845年在研究它与人口增长的关系时命名的。Logistic函数表达式为:  \n",
    "<img src=\"./data_picture/chapter7/ntjc4.png\" width=\"550\" height=\"400\" alt=\"围棋世界大战\" align=left> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）双曲正切函数tanh(x)  \n",
    "　　双曲正切函数是双曲函数的一种。在数学中，双曲函数是一类与常见的三角函数类似的函数。双曲正切函数的定义为:\n",
    "<img src=\"./data_picture/chapter7/ntjc5.png\" width=\"600\" height=\"400\" alt=\"围棋世界大战\" align=left> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3)线性整流函数ReLU(x)  \n",
    "　　线性整流函数（Rectified Linear Unit, ReLU）,又称修正线性单元, 是一种人工神经网络中常用的激活函数，通常指代以斜坡函数及其变种为代表的非线性函数。  \n",
    "<img src=\"./data_picture/chapter7/ntjc6.png\" width=\"600\" height=\"400\" alt=\"围棋世界大战\" align=left>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (二)神经网络模型损失函数\n",
    "假设一个数据集如下表：  \n",
    "<img src=\"./data_picture/chapter7/ntjc7.png\" width=\"550\" height=\"400\" alt=\"围棋世界大战\" align=left>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 注1：回归问题一般只有一个输出值，因此输出层神经元只有一个。（当然回归问题也有可能出现多标签的问题）  \n",
    "* 注2：分类问题需将原始数据集的类别进行哑变量化，生成如上表格的多标签数据集，此时输出层神经元个数就等于类别数。\n",
    "\n",
    "<img src=\"./data_picture/chapter7/ntjc8.png\" width=\"550\" height=\"400\" alt=\"围棋世界大战\" align=left>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (三)神经网络正向传播\n",
    "<img src=\"./data_picture/chapter7/ntjc9.png\" width=\"500\" height=\"400\" alt=\"围棋世界大战\" align=left> \n",
    "<img src=\"./data_picture/chapter7/ntjc10.png\" width=\"500\" height=\"400\" alt=\"围棋世界大战\" align=left>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (四)神经网络反向传播    \n",
    "<img src=\"./data_picture/chapter7/ntjc11.png\" width=\"550\" height=\"400\" alt=\"围棋世界大战\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.损失函数关于输出层对应权值的梯度（输出层前边的权值）  \n",
    "<img src=\"./data_picture/chapter7/ntjc12.png\" width=\"400\" height=\"250\" alt=\"围棋世界大战\" align=center>\n",
    "<img src=\"./data_picture/chapter7/ntjc25.png\" width=\"550\" height=\"400\" alt=\"围棋世界大战\" align=left>\n",
    "<img src=\"./data_picture/chapter7/ntjc13.png\" width=\"550\" height=\"400\" alt=\"围棋世界大战\" align=left>\n",
    "<img src=\"./data_picture/chapter7/ntjc14.png\" width=\"550\" height=\"400\" alt=\"围棋世界大战\" align=left>\n",
    "<img src=\"./data_picture/chapter7/ntjc15.png\" width=\"550\" height=\"400\" alt=\"围棋世界大战\" align=left>\n",
    "<img src=\"./data_picture/chapter7/ntjc16.png\" width=\"550\" height=\"400\" alt=\"围棋世界大战\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.损失函数关于每一个隐层对应权值的梯度（隐层前边的权值）\n",
    "<img src=\"./data_picture/chapter7/ntjc17.png\" width=\"450\" height=\"00\" alt=\"围棋世界大战\" align=center>\n",
    "<img src=\"./data_picture/chapter7/ntjc21.png\" width=\"550\" height=\"400\" alt=\"围棋世界大战\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data_picture/chapter7/ntjc18.png\" width=\"550\" height=\"400\" alt=\"围棋世界大战\" align=left>\n",
    "<img src=\"./data_picture/chapter7/ntjc22.png\" width=\"550\" height=\"400\" alt=\"围棋世界大战\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.反向传播整体过程\n",
    "<img src=\"./data_picture/chapter7/ntjc19.png\" width=\"550\" height=\"400\" alt=\"围棋世界大战\" align=left> \n",
    "<img src=\"./data_picture/chapter7/ntjc23.png\" width=\"550\" height=\"400\" alt=\"围棋世界大战\" align=left> \n",
    "<img src=\"./data_picture/chapter7/ntjc24.png\" width=\"550\" height=\"400\" alt=\"围棋世界大战\" align=left> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (五)BP网络的局限性和改进措施  \n",
    "1.BP网络的局限性  \n",
    "(1)需要较长的训练时间：这主要是由于学习速率太小所造成的，可采用变化的或自适应的学习速率来加以改进。  \n",
    "(2)完全不能训练：这主要表现在网络的麻痹上，通常为了避免这种情况的产生，一是选取较小的初始权值，而是采用较小的学习速率。  \n",
    "(3)局部最小值：这里采用的梯度下降法可能收敛到局部最小值，采用多层网络或较多的神经元，有可能得到更好的结果。  \n",
    "2.BP网络的改进措施  \n",
    "　　BP算法改进的主要目标是加快训练速度，避免陷入局部极小值等，常见的改进方法有带动量因子算法、自适应学习速率、变化的学习速率以及作用函数后缩法等。动量因子法的基本思想是在反向传播的基础上，在每一个权值的变化上加上一项正比于前次权值变化的值，并根据反向传播法来产生新的权值变化。而自适应学习 速率的方法则是针对一些特定的问题的。改变学习速率的方法的原则是，若连续几次迭代中，若目标函数对某个权倒数的符号相同，则这个权的学习速率增加， 反之若符号相反则减小它的学习速率。而作用函数后缩法则是将作用函数进行平移，即加上一个常数。  \n",
    "3.BP神经网络的过拟合问题解决办法  \n",
    "　　主要方法有：损失函数加正则化项和dropout方法。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、实例\n",
    "* 神经网络中隐层个数和每一层神经元个数是重要的超参数，因此应当通过遍历和交叉验证的手段进行调参。当然神经元个数也要注意研究问题本身特点，比如最后一个隐层神经元的个数就不能低于类别个数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实例1：利用神经网络方法做手写体数字图像识别（分类问题）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from keras.datasets import mnist   #pip install keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n##显示其中一张图片\\ndigit=train_images[4]\\nif channels==1:\\n   plt.imshow(digit,cmap=plt.cm.binary)   #显示黑白图像灰度图\\nelse:\\n   plt.imshow(digit)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.加载数据\n",
    "#只要数据导入后，再次运行时不再重新从网站上导入，但效果相当于重新导入\n",
    "(train_images,train_labels),(test_images,test_labels)=mnist.load_data()   #返回生成array数据\n",
    "print(type(train_images))\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "'''\n",
    "##显示其中一张图片\n",
    "digit=train_images[4]\n",
    "if channels==1:\n",
    "   plt.imshow(digit,cmap=plt.cm.binary)   #显示黑白图像灰度图\n",
    "else:\n",
    "   plt.imshow(digit)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 特征数据预处理\n",
    "# 神经网络对数据尺度敏感，所以最好在训练前标准化，或者归一化\n",
    "train_images = train_images.astype('float32') / 255  #标准化\n",
    "test_images = test_images.astype('float32') / 255    #标准化\n",
    "train_images=train_images.reshape((60000,28*28))   #将原始数据转换成Dense类中要求的维度（二维）\n",
    "test_images=test_images.reshape((10000,28*28))   #将原始数据转换成Dense类中要求的维度（二维）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置数据变量名字和其它分类器中用到的数据变量名字一样\n",
    "X_train=train_images\n",
    "y_train=train_labels\n",
    "X_test=test_images\n",
    "y_test=test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(256, 10), random_state=1, solver='lbfgs')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.模型训练\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier    #神经网络分类程序\n",
    "\n",
    "# hidden_layer_sizes=(256, 10)，hidden层2层,第一层256个神经元，第二层10个神经元)\n",
    "model = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(256,10), random_state=1)  \n",
    "#model = MLPClassifier(solver='adam',hidden_layer_sizes=(512), random_state=1)  \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的准确率: 1.0\n",
      "测试集的准确率:: 0.9772\n",
      "--------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.97      0.97      1032\n",
      "           3       0.97      0.97      0.97      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.98      0.98      0.98       892\n",
      "           6       0.97      0.97      0.97       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.97      0.98      0.97       974\n",
      "           9       0.97      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4.分类模型效果评估\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model_accuracy1=model.score(X_train, y_train)  #训练集的准确率\n",
    "print('训练集的准确率:',model_accuracy1)\n",
    "model_accuracy2=model.score(X_test, y_test)   #测试集的准确率\n",
    "print('测试集的准确率::',model_accuracy2)   \n",
    "print('--------------------------------------------------------------')\n",
    "\n",
    "y_predict=model.predict(X_test)        #预测新的数据分类,返回类别一维数组\n",
    "model_report=classification_report(y_test,y_predict)\n",
    "print(model_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实例2：利用神经网络方法对美国波士顿地区房价数据进行预测（回归问题）\n",
    "* 神经网络分类算法中去掉输出层的激活函数就可以做回归。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　　该数据集是一个回归问题。每个类的观察值数量是均等的，共有 506 个观察，13 个输入变量和1个输出变量。  \n",
    "　　每条数据包含房屋以及房屋周围的详细信息。其中包含城镇犯罪率，一氧化氮浓度，住宅平均房间数，到中心区域的加权距离以及自住房平均房价等等。  \n",
    "\n",
    "* CRIM：城镇人均犯罪率。  \n",
    "* ZN：住宅用地超过 25000 sq.ft. 的比例。  \n",
    "* INDUS：城镇非零售商用土地的比例。  \n",
    "* CHAS：查理斯河空变量（如果边界是河流，则为1；否则为0）。  \n",
    "* NOX：一氧化氮浓度。  \n",
    "* RM：住宅平均房间数。  \n",
    "* AGE：1940 年之前建成的自用房屋比例。  \n",
    "* DIS：到波士顿五个中心区域的加权距离。  \n",
    "* RAD：辐射性公路的接近指数。  \n",
    "* TAX：每 10000 美元的全值财产税率。  \n",
    "* PTRATIO：城镇师生比例。  \n",
    "* B：1000（Bk-0.63）^ 2，其中 Bk 指代城镇中黑人的比例。  \n",
    "* LSTAT：人口中地位低下者的比例。  \n",
    "* MEDV：自住房的平均房价，以千美元计。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.数据读入\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "data=pd.read_csv('./data_picture/chapter7/boston_house_prices.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.生成训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=data.drop('MEDV',axis=1)   #生成特征集\n",
    "y=data['MEDV']               #生成labels集\n",
    "X=X.values                   #转换为array\n",
    "y=y.values                   #转换为array\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=33,test_size=0.25)  #生成训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.数据标准化处理\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss_X=StandardScaler()\n",
    "scaler_X=ss_X.fit(X_train)\n",
    "X_train=scaler_X.transform(X_train)\n",
    "X_test=scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(15, 15), random_state=1, solver='lbfgs')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4.建立回归模型\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "#model = MLPRegressor(solver='adam', hidden_layer_sizes=(10,10), random_state=1)\n",
    "model = MLPRegressor(solver='lbfgs', hidden_layer_sizes=(15,15), random_state=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集回归评估指标：\n",
      "The accuracy of train data is 0.9773378782019437\n",
      "测试集回归评估指标：\n",
      "The accuracy of test data is 0.8529234166258169\n",
      "The value of mean_squared_error: 11.404508674676723\n",
      "The value of mean_absolute_error: 2.349917400495817\n"
     ]
    }
   ],
   "source": [
    "#6.模型评估（模型自带评估模块就是做好的评估指标）\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "\n",
    "print('训练集回归评估指标：')\n",
    "model_score1=model.score(X_train,y_train)  #使用的是和r2_score一样的方法，这个指标是否做预测值的逆变换结果都一样\n",
    "print('The accuracy of train data is',model_score1)  #其实就是拟合优度值\n",
    "\n",
    "print('测试集回归评估指标：')\n",
    "model_score2=model.score(X_test,y_test)  #使用的是和r2_score一样的方法，这个指标是否做预测值的逆变换结果都一样\n",
    "print('The accuracy of test data is',model_score2)  #其实就是拟合优度值\n",
    "\n",
    "y_test_predict=model.predict(X_test)\n",
    "mse=mean_squared_error(y_test,y_test_predict)   #均方误差\n",
    "print('The value of mean_squared_error:',mse)\n",
    "mae=mean_absolute_error(y_test,y_test_predict)  #平均绝对值误差\n",
    "print('The value of mean_absolute_error:',mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.84264226 23.49550103]\n"
     ]
    }
   ],
   "source": [
    "#7.对新的未知数据做预测\n",
    "#此处做预测一定要把数据逆变换回去，因为模型预测的结果是标准化后的数据。\n",
    "\n",
    "new_data=np.array([[0.22489,12.5,7.87,0,0.524,6.377,94.3,6.3467, 5.,311,15.2,392.52,20.45],\n",
    "                   [0.3489,11.5,7.7,0,0.526,6.477,94.3,16.3467, 5.,313,15.2,392.55,20.45]])\n",
    "X_new=scaler_X.transform(new_data) #标准化\n",
    "y_new=model.predict(X_new)        #预测\n",
    "print(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
