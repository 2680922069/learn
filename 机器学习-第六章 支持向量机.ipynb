{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第六章 支持向量机\n",
    "* https://www.toutiao.com/a6698315325579985420/  \n",
    "* https://blog.csdn.net/github_38325884/article/details/74418365  \n",
    "* 可以做分类也可以做回归：分类（sklearn.svm.SVC），回归（sklearn.svm.SVR）。  \n",
    "* 支持向量机主要用在分类上，回归问题本章不予讨论，感兴趣的话可以参阅下边文献:\n",
    "https://blog.csdn.net/lpsl1882/article/details/52411987  \n",
    "https://blog.csdn.net/qq_34531825/article/details/52891780"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、支持向量机方法概述  \n",
    "#### 1.支持向量机介绍  \n",
    "* 支持向量机方法本质上是二分类问题，但sklearn中的SVM函数实现了多分类算法，也就是多次利用二分类方法实现多分类。\n",
    "* 支持向量机分为：线性可分支持向量机算法（数据必须可分，否则方法不能用）、线性支持向量机算法（数据是否可分都可以用）、非线性支持向量机算法。\n",
    "* 支持向量机算法就是利用核函数实现对原数据进行高维映射，使得原数据在低维度空间不能使用线性支持向量机，但映射到高维空间的数据基本线性可分，就可以使用线性支持向量机进行分类。\n",
    "* 核函数一般和应用场景有关，有专门针对特定应用领域进行核函数开发和建模的科研人员在从事这方面的研究。但实际上也有一些通用的'万金油'核函数：多项式核函数和高斯核函数。选择核函数的一般原则：若特征个数比样本点数还多，则选取线性核函数。如果数据量很大，选择高斯核或多项式核。\n",
    "* 支持向量算法调参需要好好的熟悉一下，了解需要调整的参数以及每个参数对分类效果的影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 关于支持向量机svm.SVC()中的参数说明：  \n",
    "* (1) 高斯核函数  \n",
    "svm.SVC(C=1.0, kernel='rbf', gamma=0.01),可调参数有惩罚项C和gamma，gamma就是模型中的1/(2*sigma^2)  \n",
    "参数gamma控制着模型的复杂程度，这个值越大，模型越复杂，但容易出现过拟合；值越小，模型就越精简，但容易出现欠拟合。  \n",
    "参数C是惩罚项，C值越大意味着要求分类错误尽可能小，C越小意味着可以有更大的错误容忍。   \n",
    "* (2) 多项式核函数  \n",
    "svm.SVC(C=1.0, kernel='poly', degree=2)   #多项式核函数，可调参数有惩罚项C和多项式次数degree。  \n",
    "多项式次数degree越大，模型越复杂，非线性分类能力越强，但容易出现过拟合。  \n",
    "* (3) 线性核函数  \n",
    "svm.SVC(C=1.0, kernel='linear')        #线性核函数，可调参数只有惩罚项C。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、实例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实例：基于支持向量机方法的泰坦尼克号幸存者预测\n",
    "* 数据来源：https://www.kaggle.com/c/titanic/data  \n",
    "　　1912年4月15日，在首次航行期间，泰坦尼克号撞上冰山后沉没，2224名乘客和机组人员中有1502人遇难。这场轰动的悲剧震惊国际社会，在这次海难中导致死亡率高的原因之一是没有足够的救生艇给乘客和机组人员，虽然幸存下来有一部分的运气因素，但是还是有一些人比其他人的生存下来的可能性更高，比如妇女、儿童和上层阶级的人士。在这个学习之中，我们将用支持向量机方法来预测一些人生存的可能性。用机器学习来预测哪些乘客能更幸免于难。  \n",
    "　　数据集有891个训练样本，每个样本有11个特征，一个标签列Survived。数据集有缺失值，有字符型变量，因此数据需要做预处理。\n",
    "* 数据特征说明：  \n",
    "PassengerId: 乘客的ID，对预测没有用处  \n",
    "Survived：1代表幸存，0代表遇难.  \n",
    "Pclass：舱位等级，是很重要的特征。看过电影的读者知道，高仓位等级的乘客能更快的到达甲板，从而更容易获救。  \n",
    "Name：乘客名字，这个特征与幸存无关，对也侧没有用处。  \n",
    "Sex：乘客性别，看过电影的知道，因为救生艇数量不够，船长让妇女和儿童先上救生艇。这个是重要的特征。  \n",
    "Age：乘客年龄，儿童会优先上救生艇。  \n",
    "SibSp：兄弟姐妹及配偶同在船上的个数  \n",
    "Parch：父母或子女的个数  \n",
    "Ticket：船票号，不使用这个特征。  \n",
    "Fare：船票价格  \n",
    "Cabin：乘客所在船舱号。最早被水淹没的船舱位置,乘客的幸存概率要低一些。但这个特征的数据大量丢失,舍弃这个特征。  \n",
    "Embarked：乘客登船的港口。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass   Age  SibSp  Parch     Fare  Sex_female  \\\n",
       "PassengerId                                                              \n",
       "1                   0       3  22.0      1      0   7.2500           0   \n",
       "2                   1       1  38.0      1      0  71.2833           1   \n",
       "3                   1       3  26.0      0      0   7.9250           1   \n",
       "4                   1       1  35.0      1      0  53.1000           1   \n",
       "5                   0       3  35.0      0      0   8.0500           0   \n",
       "\n",
       "             Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "PassengerId                                                \n",
       "1                   1           0           0           1  \n",
       "2                   0           1           0           0  \n",
       "3                   0           0           0           1  \n",
       "4                   0           0           0           1  \n",
       "5                   1           0           0           1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('./data_picture/chapter6/titanic.csv',index_col=0)\n",
    "data.drop(['Name','Ticket','Cabin'],axis=1,inplace=True)\n",
    "data.dropna(how='any',inplace=True)   #删除有缺失值所在的整行\n",
    "data=pd.get_dummies(data, columns=['Sex','Embarked'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    220\n",
      "0    314\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#2.生成训练集和测试集\n",
    "X=data.drop('Survived',axis=1)\n",
    "y=data['Survived']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=33)\n",
    "print(y_train.value_counts(ascending=True,dropna=True))   #打印训练集各类别训练样本个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7401869158878505\n",
      "Best parameters: {'C': 4, 'gamma': 0.01}\n",
      "--------------------------------------------------------------\n",
      "训练集准确率: 0.850187265917603\n",
      "测试集准确率: 0.7415730337078652\n",
      "--------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79       110\n",
      "           1       0.65      0.69      0.67        68\n",
      "\n",
      "    accuracy                           0.74       178\n",
      "   macro avg       0.73      0.73      0.73       178\n",
      "weighted avg       0.74      0.74      0.74       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3.模型训练（此处可以利用交叉验证的方法选取超参数）\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV  ##遍历验证函数\n",
    "from sklearn.model_selection import ShuffleSplit  #生成交叉验证集的函数调入\n",
    "\n",
    "#参数gamma控制着模型的复杂程度，这个值越大，模型越复杂，但容易出现过拟合；值越小，模型就越精简，但容易出现欠拟合。\n",
    "#参数C是惩罚项，C值越大意味着要求分类错误尽可能小，C越小意味着可以有更大的错误容忍。\n",
    "model_svm=svm.SVC(kernel='rbf')\n",
    "par_grid = {\"C\":[0.5,1,1.5,2,2.5,3,4], \"gamma\": [0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]}  #遍历参数网格\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2)\n",
    "grid_search = GridSearchCV(model_svm, param_grid=par_grid, cv=cv)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best score:',grid_search.best_score_)   #这个得分和未来对测试集的预测精度差不多。\n",
    "print('Best parameters:',grid_search.best_params_)\n",
    "\n",
    "model=grid_search.best_estimator_  #将最佳分类器赋予model\n",
    "'''  也可以用这种方式重新构造模型，但需要重新训练模型。\n",
    "c_value=grid_search.best_params_['C']  #取出最佳C\n",
    "gamma_value=grid_search.best_params_['gamma']  #取出最佳gamma\n",
    "model=svm.SVC(C=c_value,kernel='rbf',gamma=gamma_value)\n",
    "model.fit(X_train,y_train)  #y_train可以是行向量也可以是列向量，knn会自动将y_train转换为列向量。\n",
    "'''\n",
    "#4.分类模型效果评估\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "model_train_accuracy=model.score(X_train, y_train)      #训练集的准确率\n",
    "model_test_accuracy=model.score(X_test, y_test)         #测试集的准确率\n",
    "y_predict=model.predict(X_test)                        #预测新的数据分类,返回类别一维数组\n",
    "print('--------------------------------------------------------------')\n",
    "print('训练集准确率:',model_train_accuracy)       \n",
    "print('测试集准确率:',model_test_accuracy)  \n",
    "print('--------------------------------------------------------------')\n",
    "model_report=classification_report(y_test,y_predict)\n",
    "print(model_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
