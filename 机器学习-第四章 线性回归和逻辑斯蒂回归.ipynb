{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第四章 线性回归和逻辑斯蒂回归\n",
    "* https://blog.csdn.net/joycewyj/article/details/51596797 \n",
    "* https://blog.csdn.net/qq_28827635/article/details/84679726 非常好，有模型建立、评估指标precision,recall.roc.auc范例演示及源码  \n",
    "* Sklearn 中一些线性回归算法总结:   \n",
    "https://blog.csdn.net/qq_29750461/article/details/81623783   \n",
    "* Sklearn包中的LinearRegression回归器不具有正则化功能。Lasso是加了L1正则项的线性回归，Ridge（岭回归）是加了L2正则项的线性回归。\n",
    "* from sklearn.linear_model import SGDRegressor,Lasso,LassoCV,Ridge,RidgeCV这几个回归器都在同一个模块中\n",
    "* Sklearn包中逻辑斯蒂回归分类器LogisticRegression具有正则化功能，可以设置参数进行正则化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 线性回归方法\n",
    "* 线性回归是回归方法.\n",
    "* 方法对训练数据类型无要求，可以是离散型特征，也可以是连续性特征\n",
    "* 很多非线性回归可以化为线性回归，因此实际上线性回归算法能够实现非线性回归。如原问题特征变量是x1,x2,x3,则可以增加新的特征变量x4=x1\\*x2,x5=x1\\*x1，此时对新的5个特征变量做线性回归，相当于对原来3个特征变量做非线性回归，从而实现了对原特征变量做非线性回归的目的。\n",
    "* 方法有可能出现过拟合的问题。处理手段就是降低模型难度，减少特征个数，或者采用正则化方法。\n",
    "* 方法都有可能出现欠拟合的问题。处理手段手工增加新特征变量，还可以增加多项式特征让模型变复杂，实现非线性回归。这个增加多项式特征的方法sklearn包也实现了（见下边实例1）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 线性回归成本函数\n",
    "![caption](./data_picture/chapter4/xxhgcbhs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.实例：使用线性回归算法预测波士顿房价\n",
    "　　该数据集是一个回归问题。每个类的观察值数量是均等的，共有 506 个观察，13 个输入变量和1个输出变量。  \n",
    "　　每条数据包含房屋以及房屋周围的详细信息。其中包含城镇犯罪率，一氧化氮浓度，住宅平均房间数，到中心区域的加权距离以及自住房平均房价等等。  \n",
    "\n",
    "　　CRIM：城镇人均犯罪率。  \n",
    "　　ZN：住宅用地超过 25000 sq.ft. 的比例。  \n",
    "　　INDUS：城镇非零售商用土地的比例。  \n",
    "　　CHAS：查理斯河空变量（如果边界是河流，则为1；否则为0）。  \n",
    "　　NOX：一氧化氮浓度。  \n",
    "　　RM：住宅平均房间数。  \n",
    "　　AGE：1940 年之前建成的自用房屋比例。  \n",
    "　　DIS：到波士顿五个中心区域的加权距离。  \n",
    "　　RAD：辐射性公路的接近指数。  \n",
    "　　TAX：每 10000 美元的全值财产税率。  \n",
    "　　PTRATIO：城镇师生比例。  \n",
    "　　B：1000（Bk-0.63）^ 2，其中 Bk 指代城镇中黑人的比例。  \n",
    "　　LSTAT：人口中地位低下者的比例。  \n",
    "　　MEDV：自住房的平均房价，以千美元计。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'也可以用下边的方法标准化\\nss=StandardScaler()\\nscaler=ss.fit(X_train)\\nX_train=scaler.transform(X_train)\\nX_test=scaler.transform(X_test)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.导入数据，并分为训练集和测试集\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error \n",
    "\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "print(X.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "\n",
    "#数据标准化(未对y_train,y_test做标准化处理，可以不做)\n",
    "ss=StandardScaler()\n",
    "X_train=ss.fit_transform(X_train)\n",
    "X_test=ss.transform(X_test)\n",
    "'''也可以用下边的方法标准化\n",
    "ss=StandardScaler()\n",
    "scaler=ss.fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.7239410298290111\n",
      "test_score: 0.7952617563243858\n",
      "The value of R2: 0.7952617563243858\n",
      "The value of mean_squared_error: 16.94307301383379\n",
      "The value of mean_absolute_error: 3.0142502752403417\n"
     ]
    }
   ],
   "source": [
    "#2.模型训练\n",
    "from sklearn.linear_model import LinearRegression  #导入线性回归器\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_score = model.score(X_train, y_train)   #训练集得分\n",
    "test_score = model.score(X_test, y_test)   #测试集得分\n",
    "print('train_score:',train_score)\n",
    "print('test_score:',test_score)\n",
    "\n",
    "y_test_predict=model.predict(X_test)\n",
    "R2=r2_score(y_test,y_test_predict)   #均方误差\n",
    "print('The value of R2:',R2)\n",
    "mse=mean_squared_error(y_test,y_test_predict)   #均方误差\n",
    "print('The value of mean_squared_error:',mse)\n",
    "mae=mean_absolute_error(y_test,y_test_predict)  #平均绝对值误差\n",
    "print('The value of mean_absolute_error:',mae)\n",
    "#说明：模型拟合效果一般，欠拟合，解决办法是增加训练样本个数或增加多项式特征即增加模型的复杂度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](./data_picture/chapter4/hgt1.png)\n",
    "![caption](./data_picture/chapter4/hgt2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score： R2= 0.9304505212799031\n",
      "test_score=： R2= 0.8604940870989192\n",
      "The value of mean_squared_error: MSE= 11.544784333939646\n",
      "The value of mean_absolute_error: MAE= 2.58983704810049\n"
     ]
    }
   ],
   "source": [
    "#3.模型优化\n",
    "#采取了数据归一化和增加多项式特征两种手段。\n",
    "#数据归一化一般情况下无法提升算法的准确性，但能加快算法的收敛速度。\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#对X_train和X_test数据增加多项式特征，返回增加多项式特征后的数据.\n",
    "\n",
    "polynomial_features = PolynomialFeatures(degree=2)  #生成实例\n",
    "X_train1=polynomial_features.fit_transform(X_train) \n",
    "X_test1=polynomial_features.fit_transform(X_test)   \n",
    "\n",
    "model=LinearRegression()\n",
    "model.fit(X_train1,y_train)\n",
    "\n",
    "train_score = model.score(X_train1, y_train)\n",
    "test_score = model.score(X_test1, y_test)\n",
    "print('train_score：','R2=',train_score)\n",
    "print('test_score=：','R2=',test_score)\n",
    "y_test_predict=model.predict(X_test1)\n",
    "mse=mean_squared_error(y_test,y_test_predict)   #均方误差\n",
    "print('The value of mean_squared_error:','MSE=',mse)\n",
    "mae=mean_absolute_error(y_test,y_test_predict)  #平均绝对值误差\n",
    "print('The value of mean_absolute_error:','MAE=',mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、逻辑斯蒂回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.逻辑斯蒂回归\n",
    "* 逻辑斯蒂回归是二分类方法,但sklearn中的逻辑斯蒂回归函数实现了多分类算法，也就是多次利用二分类方法实现多分类。\n",
    "* 方法对训练数据类型无要求，可以是离散型特征，也可以是连续性特征\n",
    "* 逻辑斯蒂回归本质上也是一种线性分类器，就是用线性函数曲线将超平面分成两部分。和线性回归一样，也可以实现非线性分类。\n",
    "* 方法有可能出现过拟合的问题。处理手段就是降低模型难度，减少特征个数，或者采用正则化方法。\n",
    "* 方法有可能出现欠拟合的问题。处理手段手工增加新特征变量，还可以增加多项式特征让模型变复杂，实现非线性分类。这个增加多项式特征的方法sklearn包也实现了（见下边实例1）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.逻辑斯蒂回归成本函数\n",
    "![caption](./data_picture/chapter4/ljsdcbhs1.png)\n",
    "![caption](./data_picture/chapter4/ljsdcbhs2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.多分类问题成本函数的说明\n",
    "![caption](./data_picture/chapter4/dflcbhs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.实例:  使用逻辑斯蒂回归方法对信用卡欺诈数据进行分类\n",
    "* https://www.kesci.com/home/dataset/5b56a592fc7e9000103c0442  （数据集背景说明）\n",
    "* 这个例子使用的是DataFrame输入数据而非array数据，Sklearn包都支持。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 逻辑斯蒂回归是二分类方法,但sklearn中的逻辑斯蒂回归函数实现了多分类算法。\n",
    "* 逻辑斯蒂回归本质上也是一种线性分类器，就是用线性函数曲线将超平面分成两部分。和上边讲的内容一样，通过增加多项式特征也可以实现非线性分类。\n",
    "* from sklearn.linear_model import LogisticRegression 这个分类器可以设置正则化功能,但只能做L2正则化。  \n",
    "* from sklearn.linear_model import LogisticRegressionCV 带有参数遍历功能选择超参数alpha  \n",
    "* from sklearn.linear_model import SGDClassifier  可以设置正则化功能，并且是随机梯度分类器,数据量大的时候用这个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据说明  \n",
    "　　信用卡支付为日常生活中常见的一种支付方式。当然，交易中也会存在着欺诈(信用卡被盗刷)行为。如果可以利用机器学习完成对欺诈情况的预测，有助于发卡机构实现反欺诈，保护持卡人的财产安全。  \n",
    "　　在284807条交易记录中共包含492条欺诈记录。显然，数据集是不平衡的，欺诈这个类别仅仅占了0.172%。  \n",
    "　　特征V1,V2,...V28分别是通过PCA变换得到的主成成分。没有做PCA变换的变量是 Time 和 Amount  \n",
    "　　Time：数据集中第一条记录与本条记录的时间差值(seconds elapsed),秒为单位。\n",
    "#### 特征名具体含义\n",
    "　　V1-V28：PCA变换后的主成分，没有实际意义。  \n",
    "　　Amount：该条交易记录的金额。  \n",
    "　　Class:类别是否为欺诈：1-是，0-否。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import imblearn   #导入一个实现下采样和过采样的包（提前下载安装了）pip install imblearn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.载入数据并生成训练集和测试集\n",
    "\n",
    "data=pd.read_csv('./data_picture/chapter4/creditcard.csv') \n",
    "X = data.drop('Class',axis=1)\n",
    "y = data['Class']\n",
    "X=X.drop('Time',axis=1)\n",
    "X['Amount'] = (X['Amount'] - X['Amount'].min()) /(X['Amount'].max() - X['Amount'].min())  #数据预处理\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    213224\n",
      "1    213224\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#2.数据分成训练集和测试集\n",
    "from sklearn.model_selection import train_test_split #该函数也可以作用在array上\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=1)\n",
    "from imblearn.over_sampling import SMOTE  # 上过采样处理库SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler  \n",
    "\n",
    "model_sample = SMOTE(random_state=0)                #smote方法过采样    \n",
    "                \n",
    "X_train, y_train= model_sample.fit_sample(X_train, y_train) \n",
    "print(y_train.value_counts(ascending=True,dropna=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score= 0.9504605485311222\n",
      "test_score= 0.9806044774023202\n",
      "------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     71091\n",
      "           1       0.07      0.88      0.12       111\n",
      "\n",
      "    accuracy                           0.98     71202\n",
      "   macro avg       0.53      0.93      0.56     71202\n",
      "weighted avg       1.00      0.98      0.99     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2.模型训练\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV,SGDClassifier\n",
    "model = LogisticRegression(penalty='l2',random_state=33)\n",
    "model.fit(X_train, y_train)    #X_train是二维数组，y_train是一维数组\n",
    "ypred1=model.predict(X_test)   #预测测试集各样本的类别\n",
    "ypred2=model.predict_proba(X_test)   #预测测试集每个样本属于各类的概率\n",
    "train_score = model.score(X_train, y_train)   \n",
    "test_score = model.score(X_test, y_test)\n",
    "print('train_score=',train_score)\n",
    "print('test_score=',test_score)\n",
    "print('------------------------------------------------------')\n",
    "y_predict=model.predict(X_test)\n",
    "model_report=classification_report(y_test,y_predict)\n",
    "print(model_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](./data_picture/chapter4/ljstt1.png)\n",
    "![caption](./data_picture/chapter4/ljstt2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score= 0.9964661576557986\n",
      "test_score= 0.993974888345833\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     71091\n",
      "           1       0.18      0.78      0.29       111\n",
      "\n",
      "    accuracy                           0.99     71202\n",
      "   macro avg       0.59      0.89      0.64     71202\n",
      "weighted avg       1.00      0.99      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3.模型优化（增加多项式特征，这个例子多项式特征有点偏过拟合）\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 增加多项式预处理\n",
    "def polynomial_model(degree=1, **kwarg):\n",
    "    polynomial_features = PolynomialFeatures(degree=degree,include_bias=False)\n",
    "    logistic_regression = LogisticRegression(**kwarg)\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),(\"logistic_regression\", logistic_regression)])\n",
    "    return pipeline\n",
    "\n",
    "model = polynomial_model(degree=2, penalty='l2',max_iter=200,random_state=33)  #penalty='l1'表示增加l1正则项,其最终是用在LogisticRegression(penalty='l1')中\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "print('train_score=', train_score)\n",
    "print('test_score=',test_score)\n",
    "print('-------------------------------------------------------')\n",
    "y_predict=model.predict(X_test)\n",
    "model_report=classification_report(y_test,y_predict)\n",
    "print(model_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注：关于分类模型评价指标说明：\n",
    "![caption](./data_picture/chapter4/pgt1.jpg)\n",
    "![caption](./data_picture/chapter4/pgt2.jpg)\n",
    "![caption](./data_picture/chapter4/pgt3.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
